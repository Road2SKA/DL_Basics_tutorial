{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2dab9e18",
   "metadata": {},
   "source": [
    "# DL Tutorial 1: Classification and Interpretability\n",
    "\n",
    "This notebook builds upon Michelle Lochner's [deep learning tutorial](https://github.com/MichelleLochner/ml-tutorials/blob/main/tutorial-deep-learning.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9f6430",
   "metadata": {},
   "source": [
    "### Open In Colab\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Road2SKA/DL_Basics_tutorial/blob/main/classification_and_interpretability.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab374ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install grad-cam --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb495b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "from torchsummary import summary\n",
    "\n",
    "from PIL import Image\n",
    "import time\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "from google.colab import output\n",
    "output.enable_custom_widget_manager()\n",
    "\n",
    "%pylab inline\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d98125",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf98033",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThumbnailsDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None, device=None, maxsize=None):\n",
    "        \"\"\"\n",
    "        Dataset that loads all images once and preloads them to GPU memory.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        root_dir : str\n",
    "            Root directory. Each subfolder = one class.\n",
    "        transform : torchvision.transforms, optional\n",
    "            Transforms to apply (must output a Tensor).\n",
    "        device : torch.device or str, optional\n",
    "            Device where data will be stored. Default: 'cuda' if available.\n",
    "        \"\"\"\n",
    "        self.transform = transform\n",
    "        self.device = device or torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        classes = sorted(os.listdir(root_dir))\n",
    "        self.class_to_idx = {c: i for i, c in enumerate(classes)}\n",
    "\n",
    "        self.images = []\n",
    "        self.targets = []\n",
    "        self.names = []\n",
    "\n",
    "        print(f\"ðŸ”„ Preloading dataset to {self.device}...\")\n",
    "\n",
    "        for c in classes:\n",
    "            class_dir = os.path.join(root_dir, c)\n",
    "            files = [f for f in os.listdir(class_dir) if f.lower().endswith(\".png\")]\n",
    "            if maxsize is not None:\n",
    "              files = files[:maxsize]\n",
    "\n",
    "            for f in files:\n",
    "                path = os.path.join(class_dir, f)\n",
    "                im_name = os.path.splitext(f)[0]\n",
    "\n",
    "                image = Image.open(path).convert(\"RGB\")\n",
    "\n",
    "                if self.transform:\n",
    "                    image = self.transform(image)  # Must produce a tensor\n",
    "\n",
    "                if not torch.is_tensor(image):\n",
    "                    raise TypeError(\"Transform must convert images to torch.Tensor\")\n",
    "\n",
    "                # Move to GPU NOW\n",
    "                image = image.to(self.device, non_blocking=True)\n",
    "\n",
    "                self.images.append(image)\n",
    "                self.targets.append(self.class_to_idx[c])\n",
    "                self.names.append(im_name)\n",
    "\n",
    "        self.targets = torch.tensor(self.targets, device=self.device)\n",
    "\n",
    "        print(f\"âœ… Loaded {len(self.images)} images.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"image\": self.images[idx],     # Already on GPU\n",
    "            \"name\": self.names[idx],\n",
    "            \"class\": self.targets[idx]     # Already on GPU\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacd5f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/MichelleLochner/ml-tutorials/main/data/galaxy_zoo.zip\n",
    "!unzip -q galaxy_zoo.zip -d galaxy_zoo\n",
    "!ls -orth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576a4f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = ThumbnailsDataset(\"galaxy_zoo/galaxy_zoo/training\", transform=preprocess, maxsize=None)\n",
    "test_dataset = ThumbnailsDataset(\"galaxy_zoo/galaxy_zoo/test\", transform=preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6212f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_galaxy(dataset, idx):\n",
    "    \"\"\"\n",
    "    Convenience function to make a nice image of a particular galaxy\n",
    "    \"\"\"\n",
    "    # Retrieve the image\n",
    "    im = dataset[idx]['image'].cpu().detach()\n",
    "    # For whatever reason, torch and matplotlib expect different orders of the channels so we need to permute them\n",
    "    im = im.permute(1, 2, 0)\n",
    "    # Show the image\n",
    "    imshow(im)\n",
    "    \n",
    "    # Get the class and put it in a title\n",
    "    target = dataset[idx]['class']\n",
    "    if target == 0:\n",
    "        img_class = 'elliptical'\n",
    "    else:\n",
    "        img_class = 'spiral'\n",
    "    xticks([])\n",
    "    yticks([])\n",
    "    title(img_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88a4dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick some random examples\n",
    "inds = np.random.choice(np.arange(len(training_dataset)), 9, replace=False)\n",
    "\n",
    "figure(figsize=(8,8))\n",
    "for i in range(9):\n",
    "    subplot(3,3,i+1)\n",
    "    idx = inds[i]\n",
    "    plot_galaxy(training_dataset, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cdbc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A custom CNN class\n",
    "class ConvNeuralNet(nn.Module):\n",
    "#  Determine what layers and their order in CNN object\n",
    "    def __init__(self, num_classes):\n",
    "        super(ConvNeuralNet, self).__init__()\n",
    "        self.conv_layer1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3)\n",
    "        self.conv_layer2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3)\n",
    "        self.max_pool1 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "\n",
    "        self.conv_layer3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)\n",
    "        self.conv_layer4 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3)\n",
    "        self.max_pool2 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "\n",
    "        # Dynamically calculate the input size for the first fully connected layer\n",
    "        # Create a dummy input tensor\n",
    "        dummy_input = torch.zeros(1, 3, 224, 224)\n",
    "        # Pass it through the convolutional and pooling layers\n",
    "        out = self.conv_layer1(dummy_input)\n",
    "        out = self.conv_layer2(out)\n",
    "        out = self.max_pool1(out)\n",
    "        out = self.conv_layer3(out)\n",
    "        out = self.conv_layer4(out)\n",
    "        out = self.max_pool2(out)\n",
    "        # Calculate the flattened size\n",
    "        flattened_size = out.flatten(1).shape[1]\n",
    "\n",
    "        self.fc1 = nn.Linear(flattened_size, 64)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(64, num_classes)\n",
    "\n",
    "    # Progresses data across layers\n",
    "    def forward(self, x):\n",
    "        out = self.conv_layer1(x)\n",
    "        out = self.conv_layer2(out)\n",
    "        out = self.max_pool1(out)\n",
    "\n",
    "        out = self.conv_layer3(out)\n",
    "        out = self.conv_layer4(out)\n",
    "        out = self.max_pool2(out)\n",
    "\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555c5856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a custom CNN\n",
    "classifier = ConvNeuralNet(2).to(device) \n",
    "\n",
    "# OR use a pre-defined ResNet model\n",
    "#classifier = models.resnet18(num_classes=2).to(device) \n",
    "summary(classifier, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6007fab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 3e-3\n",
    "batch_size = 64\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.SGD(classifier.parameters(), lr=learning_rate)\n",
    "\n",
    "training_dataloader = DataLoader(training_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "train_losses, test_losses, train_acc, test_acc = [], [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670c0201",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    \"\"\"\n",
    "    Function to iterate through the training set and train the network.\n",
    "    \"\"\"\n",
    "    losses = []\n",
    "    size = len(dataloader.dataset)\n",
    "    correct = 0\n",
    "\n",
    "    for batch, dat in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(dat['image'])\n",
    "        loss = loss_fn(pred, dat['class'])\n",
    "        correct += (pred.argmax(1) == dat['class']).type(torch.float).sum().item()\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.cpu().detach().numpy()[None])\n",
    "\n",
    "        if False: #batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(dat['image'])\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "    \n",
    "    correct /= size\n",
    "    return np.concatenate(losses), np.array([100*correct])\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    \"\"\"\n",
    "    Function to iterate through the test data and evaluate the algorithm.\n",
    "    \"\"\"\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        for dat in dataloader:\n",
    "            pred = model(dat['image'])\n",
    "            test_loss += loss_fn(pred, dat['class']).item()\n",
    "            correct += (pred.argmax(1) == dat['class']).type(torch.float).sum().item()\n",
    "    \n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test accuracy: {(100*correct):>0.1f}%, avg loss: {test_loss:>8f} \")\n",
    "    return np.array([test_loss]), np.array([100*correct])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e89246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we actually iterate through each epoch, checking performance as we go.\n",
    "t1 = time.perf_counter()\n",
    "epochs = 50\n",
    "\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\")\n",
    "    trainloss, trainacc = train_loop(training_dataloader, classifier, loss_fn, optimizer)\n",
    "    testloss, testacc = test_loop(test_dataloader, classifier, loss_fn)\n",
    "    train_losses.append(trainloss)\n",
    "    test_losses.append(testloss)\n",
    "    train_acc.append(trainacc)\n",
    "    test_acc.append(testacc)\n",
    "all_train_losses = np.concatenate(train_losses)\n",
    "all_test_losses = np.concatenate(test_losses)\n",
    "all_train_acc = np.concatenate(train_acc)\n",
    "all_test_acc = np.concatenate(test_acc)\n",
    "\n",
    "print(\"Done!\")\n",
    "print(f\"Time taken {time.perf_counter()-t1:.2f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3d42d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = np.linspace(0, epochs-1, all_train_losses.size)\n",
    "btch_per_epoch = int(all_train_losses.size/epochs)\n",
    "\n",
    "figure(figsize=(9,4))\n",
    "\n",
    "subplot(1,2,1)\n",
    "plot(batches, all_train_losses)\n",
    "plot(batches[::btch_per_epoch]+1, all_test_losses)\n",
    "xlabel('Epoch')\n",
    "ylabel('Loss')\n",
    "grid()\n",
    "print(all_train_losses.size)\n",
    "subplot(1,2,2)\n",
    "plot(batches[::btch_per_epoch]+1, all_train_acc)\n",
    "plot(batches[::btch_per_epoch]+1, all_test_acc)\n",
    "xlabel('Epoch')\n",
    "ylabel('Accuracy')\n",
    "grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878a3bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect a set of predictions for the test data\n",
    "predictions = []\n",
    "targets = []\n",
    "test_imgs = []\n",
    "with torch.no_grad():\n",
    "    for dat in test_dataloader:\n",
    "        pred = classifier(dat['image'])\n",
    "        predictions += list(pred.argmax(1).cpu().detach().numpy())\n",
    "        targets += list(dat['class'].cpu().detach().numpy())\n",
    "        test_imgs += list(dat['image'].cpu().detach().numpy().transpose(0,2,3,1))\n",
    "targets = np.array(targets)\n",
    "predictions = np.array(predictions)\n",
    "test_imgs = np.array(test_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819a464f",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_inds = np.random.choice(np.arange(len(targets))[targets==predictions], 9, replace=False)\n",
    "figure(figsize=(9,9))\n",
    "for i in range(9):\n",
    "    subplot(3,3,i+1)\n",
    "    idx = correct_inds[i]\n",
    "    imshow(test_imgs[idx])\n",
    "    axis('off')\n",
    "    title(\"Spiral\" if targets[idx]==1 else \"Ellipsoidal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22faef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_inds = np.random.choice(np.arange(len(targets))[targets!=predictions], 9, replace=False)\n",
    "figure(figsize=(9,9))\n",
    "for i in range(9):\n",
    "    subplot(3,3,i+1)\n",
    "    idx = wrong_inds[i]\n",
    "    imshow(test_imgs[idx])\n",
    "    axis('off')\n",
    "    title(\"Spiral\" if targets[idx]==1 else \"Ellipsoidal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abd4ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "cm = confusion_matrix(targets, predictions)\n",
    "disp = ConfusionMatrixDisplay(cm, display_labels=['elliptical', 'spiral'])\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cb1a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_layers = [classifier.conv_layer4] #for resnet use classifier.layer4[-1]\n",
    "cam = GradCAM(model=classifier, target_layers=target_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b771eab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_inds = np.random.choice(np.arange(len(targets))[targets==predictions], 9, replace=False)\n",
    "figure(figsize=(9,9))\n",
    "for i in range(9):\n",
    "    subplot(3,3,i+1)\n",
    "    idx = correct_inds[i]\n",
    "    #targets_cam = [ClassifierOutputTarget()]\n",
    "    input_tensor = torch.from_numpy(test_imgs[idx][None].transpose(0,3,1,2))\n",
    "    grayscale_cam = cam(input_tensor=input_tensor) #, targets=targets_cam)\n",
    "    grayscale_cam = grayscale_cam[0, :]\n",
    "    visualization = show_cam_on_image(test_imgs[idx], grayscale_cam, use_rgb=True, image_weight=0.8)\n",
    "    imshow(visualization)\n",
    "    title(f\"True {targets[idx]}, Pred {predictions[idx]}\")\n",
    "    axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414d7eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_inds = np.random.choice(np.arange(len(targets))[targets!=predictions], 9, replace=False)\n",
    "figure(figsize=(9,9))\n",
    "for i in range(9):\n",
    "    subplot(3,3,i+1)\n",
    "    idx = wrong_inds[i]\n",
    "    #targets_cam = [ClassifierOutputTarget()]\n",
    "    input_tensor = torch.from_numpy(test_imgs[idx][None].transpose(0,3,1,2))\n",
    "    grayscale_cam = cam(input_tensor=input_tensor) #, targets=targets_cam)\n",
    "    grayscale_cam = grayscale_cam[0, :]\n",
    "    visualization = show_cam_on_image(test_imgs[idx], grayscale_cam, use_rgb=True, image_weight=0.8)\n",
    "    imshow(visualization)\n",
    "    title(f\"True {targets[idx]}, Pred {predictions[idx]}\")\n",
    "    axis('off')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
